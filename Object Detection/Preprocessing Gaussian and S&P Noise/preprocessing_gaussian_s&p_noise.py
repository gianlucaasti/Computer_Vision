# -*- coding: utf-8 -*-
"""Preprocessing_Gaussian_S&P_Noise

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z2qLr2-puUHWv44PMyHtl5QnnzytydPL

**IMPORT LIBRARIES**
"""

# Commented out IPython magic to ensure Python compatibility.
import skimage
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2
import ast
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

PATH = 'D:/Pictures/dataset/new_images/train.csv'
IMG_ROOT = 'D:/Pictures/dataset/new_images/train/'

"""**IMPORT CSV AND PLOT IMAGES**"""

# Get image as numpy array
def load_image(name, path):
    img_path = path + name
    img = cv2.imread(img_path)
    return img

# Plot numpy array
def plot_image(img):
    plt.imshow(img)
    plt.title(img.shape)
    
# Plot a grid of examples
def plot_grid(img_names, img_root, rows=5, cols=5):
    fig = plt.figure(figsize=(25,25))
    
    for i,name in enumerate(img_names):
        fig.add_subplot(rows,cols,i+1)
        img = load_image(name, img_root)
        plot_image(img)
        
    plt.show()

data = pd.read_csv(PATH, delimiter=',')
data.head()

name = 'BloodImage_00322.jpg'
img = load_image(name, IMG_ROOT)
plot_image(img)

"""**Create new images and create new excel files with classes, new names and bounding boxes**"""

def add_noise(clr_img):
  noise_img=skimage.util.random_noise(clr_img, mode='s&p')
  noise_img=skimage.util.random_noise(noise_img, mode='gaussian')
  return noise_img

def concat_name(row_old_name):
  pd.concat(row_old_name['img_name'+'_augmented_'+i])
  return new_name

campione=data[data['class']=='Platelets']

univoci=pd.DataFrame(campione['img_name'].unique(), columns=['img_name'])
sample_to_augment=univoci.sample(n=60,replace=True)
new_df=pd.DataFrame()
i=0
for element in sample_to_augment['img_name']:
  img = load_image(element, IMG_ROOT)
  new_img=add_noise(img)
  name_no_ext=element.split(".")[0]
  new_name=name_no_ext+'_augmented_'+str(i)+'_.jpg'
  new_img = cv2.convertScaleAbs(new_img, alpha=(255.0))
  cv2.imwrite(IMG_ROOT+new_name,new_img)
  new_df=new_df.append({'new_img_name':new_name},ignore_index = True)
  i=i+1

sample_to_augment=sample_to_augment.reset_index()
new_df=new_df.reset_index()
final_df=pd.concat((sample_to_augment,new_df), axis=1)

subsample=pd.merge(data,final_df,on='img_name')
print(subsample)
subsample.to_csv("D:/Pictures/dataset/new_images/subsample.csv",index=False,header=False)  # This CSV will be use in training

#platelets, WBC

campione=data[data['class']=='WBC']

univoci=pd.DataFrame(campione['img_name'].unique(), columns=['img_name'])
sample_to_augment=univoci.sample(n=60,replace=True)
new_df=pd.DataFrame()
i=0
for element in sample_to_augment['img_name']:
  img = load_image(element, IMG_ROOT)
  new_img=add_noise(img)
  name_no_ext=element.split(".")[0]
  new_name=name_no_ext+'_augmented_'+str(i)+'_.jpg'
  new_img = cv2.convertScaleAbs(new_img, alpha=(255.0))
  cv2.imwrite(IMG_ROOT+new_name,new_img)
  new_df=new_df.append({'new_img_name':new_name},ignore_index = True)
  i=i+1

sample_to_augment=sample_to_augment.reset_index()
new_df=new_df.reset_index()
final_df=pd.concat((sample_to_augment,new_df), axis=1)

subsample=pd.merge(data,final_df,on='img_name')
print(subsample)
subsample.to_csv("D:/Pictures/dataset/new_images/subsample.csv",index=False,header=False)  # This CSV will be use in training